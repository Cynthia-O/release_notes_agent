{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a912847-bac2-4a7f-8074-1fee1eab8d91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Drafting a release notes agent for Databricks on AWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f39bdd5-67bf-4f3c-adf9-71cb88dd7639",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Lock down some important packages\n",
    "%pip install -U -qqqq mlflow langchain langgraph==0.3.4 databricks-langchain pydantic databricks-agents unitycatalog-langchain[databricks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d5da5c3-1878-490f-b729-4dd4369be2ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5cb9897-d0db-4949-aea5-16526686b486",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Databricks AWS Release Notes Agent\n",
    "\n",
    "This script creates an AI agent that can answer questions about Databricks AWS release notes,\n",
    "focusing on recent features and capabilities including cost optimization, AI/BI dashboarding,\n",
    "vector database handling, agentic work, and external data access features.\n",
    "\n",
    "Let's get this party started.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from typing import Any, Optional, Sequence, Union, List, Dict\n",
    "\n",
    "# Databricks and MLflow imports\n",
    "from databricks_langchain import ChatDatabricks\n",
    "from databricks_langchain.uc_ai import (\n",
    "    DatabricksFunctionClient,\n",
    "    UCFunctionToolkit,\n",
    "    set_uc_function_client,\n",
    ")\n",
    "import mlflow\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.graph import CompiledGraph\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.langchain.chat_agent_langgraph import ChatAgentState, ChatAgentToolNode\n",
    "from mlflow.pyfunc import ChatAgent\n",
    "from mlflow.types.agent import (\n",
    "    ChatAgentMessage,\n",
    "    ChatAgentResponse,\n",
    "    ChatContext,\n",
    ")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Enable MLflow autologging\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce4d7f53-89a6-48c3-a12f-ec0fb2170165",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Ok, now that we've waded through some rather dicey imports to a short-lived imports equilibrium, let's try creating this agent..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a0e0f2a-17a7-4eaa-952a-7c35ac9767ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def scrape_release_notes() -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Scrapes release notes from Databricks AWS documentation.\n",
    "    Returns a DataFrame with release note content and metadata.\n",
    "    \n",
    "    For demo purposes, creates synthetic data. In production, implement actual web scraping.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Base URL for Databricks AWS release notes\n",
    "    base_url = \"https://docs.databricks.com/aws/en/release-notes/product/\"\n",
    "    \n",
    "    # Synthetic release notes data for demonstration\n",
    "    synthetic_release_notes = [\n",
    "        {\n",
    "            \"content\": \"Databricks Runtime 15.3 LTS introduces enhanced cost optimization features including automatic cluster scaling based on workload patterns, improved spot instance utilization, and real-time cost monitoring dashboards. These features help reduce compute costs by up to 40% while maintaining performance.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/runtime/15.3.html\",\n",
    "            \"release_date\": \"2024-12-15\",\n",
    "            \"category\": \"cost_optimization\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"New AI-powered dashboard builder allows users to create interactive BI dashboards using natural language queries. The feature includes automatic chart selection, smart data aggregation, and real-time collaboration capabilities. Supports integration with Unity Catalog for secure data access.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/dashboards/ai-builder.html\",\n",
    "            \"release_date\": \"2024-12-10\",\n",
    "            \"category\": \"ai_bi_dashboarding\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Vector Search capabilities enhanced with support for hybrid search combining dense vector embeddings with traditional keyword search. New features include automatic embedding generation, similarity threshold controls, and integration with popular vector databases like Pinecone and Weaviate.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/vector-search/enhancements.html\",\n",
    "            \"release_date\": \"2024-12-08\",\n",
    "            \"category\": \"vector_database\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Agent Framework now supports multi-step reasoning with memory persistence across sessions. New capabilities include tool chaining, conditional logic execution, and integration with external APIs. Agents can now maintain context and learn from previous interactions.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/agents/multi-step.html\",\n",
    "            \"release_date\": \"2024-12-05\",\n",
    "            \"category\": \"agentic_work\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"External data access enhanced with new connectors for Snowflake, BigQuery, and Redshift. Features include automatic schema inference, incremental data loading, and unified governance through Unity Catalog. Performance optimizations reduce query times by up to 60%.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/external-data/connectors.html\",\n",
    "            \"release_date\": \"2024-12-01\",\n",
    "            \"category\": \"external_data_access\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Cost control features expanded with budget alerts, resource tagging automation, and predictive cost forecasting. New dashboard provides granular cost breakdown by workspace, cluster, and user. Integration with AWS Cost Explorer for comprehensive cost management.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/cost-control/enhanced.html\",\n",
    "            \"release_date\": \"2024-11-28\",\n",
    "            \"category\": \"cost_optimization\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"AI/ML capabilities enhanced with new AutoML features for time series forecasting and anomaly detection. Improved model registry with version control, A/B testing framework, and automated model deployment pipelines. Support for custom model serving with GPU acceleration.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/ml/automl-enhancements.html\",\n",
    "            \"release_date\": \"2024-11-25\",\n",
    "            \"category\": \"ai_bi_dashboarding\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Vector database performance improvements with new indexing algorithms and parallel processing capabilities. Support for real-time vector updates and streaming ingestion. Enhanced query optimization for large-scale vector similarity search operations.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/vector-search/performance.html\",\n",
    "            \"release_date\": \"2024-11-20\",\n",
    "            \"category\": \"vector_database\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Agent development tools enhanced with visual workflow builder and debugging capabilities. New agent marketplace for sharing and discovering pre-built agents. Improved monitoring and observability for agent performance and reliability.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/agents/development-tools.html\",\n",
    "            \"release_date\": \"2024-11-18\",\n",
    "            \"category\": \"agentic_work\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"External data federation capabilities expanded with support for Delta Lake format across multiple cloud providers. New data virtualization features enable querying external data sources without data movement. Enhanced security with row-level security and column-level encryption.\",\n",
    "            \"doc_uri\": \"https://docs.databricks.com/aws/en/release-notes/external-data/federation.html\",\n",
    "            \"release_date\": \"2024-11-15\",\n",
    "            \"category\": \"external_data_access\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return pd.DataFrame(synthetic_release_notes)\n",
    "\n",
    "\n",
    "def extract_release_notes_keywords(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extracts keywords from release notes text, focusing on technical features and capabilities.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text from release notes.\n",
    "    Returns:\n",
    "        List[str]: List of extracted keywords in order of importance.\n",
    "    \"\"\"\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    import re\n",
    "    \n",
    "    # Clean and preprocess text\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
    "    \n",
    "    def extract_keywords(text, top_n=8):\n",
    "        \"\"\"Extracts top keywords from release notes text\"\"\"\n",
    "        # Custom stop words for release notes context\n",
    "        custom_stop_words = [\n",
    "            'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by',\n",
    "            'new', 'enhanced', 'improved', 'updated', 'added', 'support', 'feature', 'capability'\n",
    "        ]\n",
    "        \n",
    "        vectorizer = TfidfVectorizer(\n",
    "            stop_words=custom_stop_words,\n",
    "            ngram_range=(1, 2),  # Include bigrams for technical terms\n",
    "            max_features=100\n",
    "        )\n",
    "        \n",
    "        tfidf = vectorizer.fit_transform([text])\n",
    "        scores = tfidf.toarray()[0]\n",
    "        indices = scores.argsort()[-top_n:][::-1]\n",
    "        \n",
    "        return [vectorizer.get_feature_names_out()[i] for i in indices if scores[i] > 0]\n",
    "    \n",
    "    return extract_keywords(text)\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    agent_prompt: Optional[str] = None,\n",
    ") -> CompiledGraph:\n",
    "    \"\"\"\n",
    "    Creates a tool-calling agent using LangGraph.\n",
    "    \n",
    "    Args:\n",
    "        model: The language model to use\n",
    "        tools: List of tools the agent can use\n",
    "        agent_prompt: Optional system prompt for the agent\n",
    "    \n",
    "    Returns:\n",
    "        CompiledGraph: The compiled agent workflow\n",
    "    \"\"\"\n",
    "    model = model.bind_tools(tools)\n",
    "\n",
    "    def routing_logic(state: ChatAgentState):\n",
    "        last_message = state[\"messages\"][-1]\n",
    "        if last_message.get(\"tool_calls\"):\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    if agent_prompt:\n",
    "        system_message = {\"role\": \"system\", \"content\": agent_prompt}\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [system_message] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "    model_runnable = preprocessor | model\n",
    "\n",
    "    def call_model(\n",
    "        state: ChatAgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "    \n",
    "    workflow = StateGraph(ChatAgentState)\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))\n",
    "    workflow.add_node(\"tools\", ChatAgentToolNode(tools))\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        routing_logic,\n",
    "        {\n",
    "            \"continue\": \"tools\",\n",
    "            \"end\": END,\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "class ReleaseNotesAgent(ChatAgent):\n",
    "    \"\"\"\n",
    "    ChatAgent wrapper for the release notes agent.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        messages: List[ChatAgentMessage],\n",
    "        context: Optional[ChatContext] = None,\n",
    "        custom_inputs: Optional[Dict[str, Any]] = None,\n",
    "    ) -> ChatAgentResponse:\n",
    "        request = {\"messages\": self._convert_messages_to_dict(messages)}\n",
    "        output = self.agent.invoke(request)\n",
    "        return ChatAgentResponse(**output)\n",
    "\n",
    "\n",
    "def setup_release_notes_agent(\n",
    "    llm_endpoint: str = \"llama-instruct-3-3-70b\",\n",
    "    catalog: str = \"main\",\n",
    "    schema: str = \"default\"\n",
    ") -> ReleaseNotesAgent:\n",
    "    \"\"\"\n",
    "    Sets up and returns a configured release notes agent.\n",
    "    \n",
    "    Args:\n",
    "        llm_endpoint: The LLM endpoint to use\n",
    "        catalog: Unity Catalog catalog name\n",
    "        schema: Unity Catalog schema name\n",
    "    \n",
    "    Returns:\n",
    "        ReleaseNotesAgent: Configured agent ready for use\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configure LLM\n",
    "    llm = ChatDatabricks(endpoint=llm_endpoint)\n",
    "    \n",
    "    # Load release notes data\n",
    "    release_notes_df = scrape_release_notes()\n",
    "    print(f\"Loaded {len(release_notes_df)} release notes entries\")\n",
    "    \n",
    "    # Set up Unity Catalog client\n",
    "    uc_client = DatabricksFunctionClient()\n",
    "    set_uc_function_client(uc_client)\n",
    "    \n",
    "    # Create keyword extraction function in Unity Catalog\n",
    "    function_info = uc_client.create_python_function(\n",
    "        func=extract_release_notes_keywords,\n",
    "        catalog=catalog,\n",
    "        schema=schema,\n",
    "        replace=True,\n",
    "    )\n",
    "    print(f\"Created function: {function_info}\")\n",
    "    \n",
    "    # Create toolkit\n",
    "    uc_tool_names = [f\"{catalog}.{schema}.extract_release_notes_keywords\"]\n",
    "    uc_toolkit = UCFunctionToolkit(function_names=uc_tool_names)\n",
    "    \n",
    "    # Prepare documents for search\n",
    "    documents = release_notes_df\n",
    "    doc_vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
    "    tfidf_matrix = doc_vectorizer.fit_transform(documents[\"content\"])\n",
    "    \n",
    "    # Create document retrieval tool\n",
    "    @tool\n",
    "    @mlflow.trace(name=\"ReleaseNotesRetriever\", span_type=mlflow.entities.SpanType.RETRIEVER)\n",
    "    def find_relevant_release_notes(query: str, top_n: int = 5, category_filter: str = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Retrieves relevant release notes based on the query.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            top_n (int): Number of results to return (default: 5)\n",
    "            category_filter (str): Optional category filter\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of relevant release notes with metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # Filter by category if specified\n",
    "        if category_filter:\n",
    "            filtered_docs = documents[documents['category'] == category_filter]\n",
    "            if len(filtered_docs) == 0:\n",
    "                return []\n",
    "            \n",
    "            # Rebuild TF-IDF matrix for filtered documents\n",
    "            filtered_vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1, 2))\n",
    "            filtered_tfidf_matrix = filtered_vectorizer.fit_transform(filtered_docs[\"content\"])\n",
    "            query_tfidf = filtered_vectorizer.transform([query])\n",
    "            similarities = (filtered_tfidf_matrix @ query_tfidf.T).toarray().flatten()\n",
    "            ranked_docs = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            result = []\n",
    "            for idx, score in ranked_docs[:top_n]:\n",
    "                row = filtered_docs.iloc[idx]\n",
    "                result.append({\n",
    "                    \"page_content\": row[\"content\"],\n",
    "                    \"metadata\": {\n",
    "                        \"doc_uri\": row[\"doc_uri\"],\n",
    "                        \"release_date\": row[\"release_date\"],\n",
    "                        \"category\": row[\"category\"],\n",
    "                        \"score\": float(score),\n",
    "                    },\n",
    "                })\n",
    "            return result\n",
    "        \n",
    "        # Search across all documents\n",
    "        query_tfidf = doc_vectorizer.transform([query])\n",
    "        similarities = (tfidf_matrix @ query_tfidf.T).toarray().flatten()\n",
    "        ranked_docs = sorted(enumerate(similarities), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        result = []\n",
    "        for idx, score in ranked_docs[:top_n]:\n",
    "            row = documents.iloc[idx]\n",
    "            result.append({\n",
    "                \"page_content\": row[\"content\"],\n",
    "                \"metadata\": {\n",
    "                    \"doc_uri\": row[\"doc_uri\"],\n",
    "                    \"release_date\": row[\"release_date\"],\n",
    "                    \"category\": row[\"category\"],\n",
    "                    \"score\": float(score),\n",
    "                },\n",
    "            })\n",
    "        return result\n",
    "    \n",
    "    # Create specialized system prompt\n",
    "    release_notes_system_prompt = \"\"\"\n",
    "    You are a specialized assistant that answers questions about Databricks AWS release notes and recent features. \n",
    "    You have access to detailed information about recent Databricks capabilities including:\n",
    "\n",
    "    - Cost optimization and control features\n",
    "    - AI/BI dashboarding capabilities  \n",
    "    - Vector database and search features\n",
    "    - Agentic work and automation capabilities\n",
    "    - External data access and federation features\n",
    "\n",
    "    When answering questions:\n",
    "    1. Focus on recent features and capabilities (last 3-6 months)\n",
    "    2. Provide specific details about what was released and when\n",
    "    3. Include performance improvements and benefits where available\n",
    "    4. Reference the specific release notes and documentation links\n",
    "    5. If asked about trends, analyze which capabilities Databricks has been building most rapidly\n",
    "\n",
    "    You have access to tools that can search through release notes and extract relevant keywords. \n",
    "    Use these tools to provide accurate, up-to-date information about Databricks AWS features.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create the agent\n",
    "    agent = create_tool_calling_agent(\n",
    "        llm, \n",
    "        tools=[*uc_toolkit.tools, find_relevant_release_notes],\n",
    "        agent_prompt=release_notes_system_prompt\n",
    "    )\n",
    "    \n",
    "    # Create and return the ChatAgent wrapper\n",
    "    return ReleaseNotesAgent(agent=agent)\n",
    "\n",
    "\n",
    "def test_agent(agent: ReleaseNotesAgent):\n",
    "    \"\"\"\n",
    "    Test the agent with sample questions.\n",
    "    \n",
    "    Args:\n",
    "        agent: The configured release notes agent\n",
    "    \"\"\"\n",
    "    test_questions = [\n",
    "        \"What are the most recent features that Databricks on AWS has released to control costs?\",\n",
    "        \"What capabilities, such as external data access, or AI/BI dashboarding, or vector database handling, or agentic work, has Databricks been building out most rapidly over the last three months?\",\n",
    "        \"What are the latest vector database features in Databricks?\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        response = agent.predict({\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": question}]\n",
    "        })\n",
    "        print(f\"\\nAnswer: {response.content}\")\n",
    "        print(f\"\\n{'-'*80}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to set up and test the release notes agent.\n",
    "    \"\"\"\n",
    "    print(\"Setting up Databricks AWS Release Notes Agent...\")\n",
    "    \n",
    "    # Set up the agent\n",
    "    agent = setup_release_notes_agent()\n",
    "    \n",
    "    print(\"Agent setup complete! Testing with sample questions...\")\n",
    "    \n",
    "    # Test the agent\n",
    "    test_agent(agent)\n",
    "    \n",
    "    print(\"\\nRelease Notes Agent is ready for use!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "590f0382-9e5f-452e-a98e-8f83006252ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aa86179-c5b9-435f-b7bb-fc6857250365",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6574739d-1fed-42b5-ab30-95fe2a9b4803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a5b23b6-cbcd-49ea-b28a-b36afc157ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simple usage\n",
    "from release_notes_agent import setup_release_notes_agent\n",
    "\n",
    "# Set up the agent\n",
    "agent = setup_release_notes_agent()\n",
    "\n",
    "# Ask questions\n",
    "response = agent.predict({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"What are the latest cost optimization features?\"}]\n",
    "})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0a4e24e7-b67e-4e5e-bd75-a9ad72db6fcc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# To run the script:\n",
    "# cd Databricks/release_notes_agent\n",
    "# python release_notes_agent.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7029ef0-a125-40e7-9df4-4e18e96bc86b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Databricks_AWS_release_notes_agent",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
